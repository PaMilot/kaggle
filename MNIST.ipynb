{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1fe657a96d0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pylab as plt\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "# from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "import pandas as pd\n",
    "\n",
    "torch.manual_seed(2)\n",
    "\n",
    "# https://www.kaggle.com/competitions/digit-recognizer/overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"train.csv\")\n",
    "labels = train_df['label'].values\n",
    "pixels = train_df.drop(columns=['label']).values\n",
    "\n",
    "class MNIST_train(Dataset):\n",
    "    def __init__(self, pixels, labels):\n",
    "        self.pixels = torch.tensor(pixels, dtype=torch.float32).view(-1, 1, 28, 28) / 255.0  # Normalize to [0, 1]\n",
    "        self.labels = torch.tensor(labels, dtype=torch.long)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.pixels[idx], self.labels[idx]\n",
    "\n",
    "\n",
    "mnist_dataset = MNIST_train(pixels, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(0.80 * len(mnist_dataset))\n",
    "val_size = len(mnist_dataset) - train_size\n",
    "\n",
    "train_dataset, val_dataset = random_split(mnist_dataset, [train_size, val_size])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True,drop_last=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv(\"test.csv\")\n",
    "pixels = test_df.values\n",
    "\n",
    "class MNIST_test(Dataset):\n",
    "    def __init__(self, pixels):\n",
    "        self.pixels = torch.tensor(pixels, dtype=torch.float32).view(-1, 1, 28, 28) / 255.0  # Normalize to [0, 1]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(test_df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.pixels[idx]\n",
    "\n",
    "# Instantiate dataset\n",
    "mnist_dataset_test = MNIST_test(pixels) # pixels ???\n",
    "\n",
    "# Create DataLoader\n",
    "test_loader = DataLoader(mnist_dataset_test, batch_size=64, shuffle=False, drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, criterion, train_loader, test_loader, optimizer, epochs=10):\n",
    "    i = 0\n",
    "    output = {'training_loss': [], 'test_accuracy': []}  \n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        print(str(epoch) + \" / \" + str(epochs))\n",
    "        for i, (image, pred) in enumerate(train_loader):\n",
    "            optimizer.zero_grad()\n",
    "            z = model(image)\n",
    "            loss = criterion(z, pred)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            output['training_loss'].append(loss.data.item())\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PaulNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(PaulNet, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(1, 8, kernel_size=5, stride = 1, padding = 0)\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "\n",
    "        self.fc1 = nn.Linear(12*12*8, 56)\n",
    "        self.fc2 = nn.Linear(56, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.conv1(x))\n",
    "        out = self.pool1(out)\n",
    "        out = out.view(-1, 12*12*8)\n",
    "\n",
    "        out = F.relu(self.fc1(out))\n",
    "        out = self.fc2(out)\n",
    "        # out = F.softmax(out, dim=1)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 / 100\n",
      "1 / 100\n",
      "2 / 100\n",
      "3 / 100\n",
      "4 / 100\n",
      "5 / 100\n",
      "6 / 100\n",
      "7 / 100\n",
      "8 / 100\n",
      "9 / 100\n",
      "10 / 100\n",
      "11 / 100\n",
      "12 / 100\n",
      "13 / 100\n",
      "14 / 100\n",
      "15 / 100\n",
      "16 / 100\n",
      "17 / 100\n",
      "18 / 100\n",
      "19 / 100\n",
      "20 / 100\n",
      "21 / 100\n",
      "22 / 100\n",
      "23 / 100\n",
      "24 / 100\n",
      "25 / 100\n",
      "26 / 100\n",
      "27 / 100\n",
      "28 / 100\n",
      "29 / 100\n",
      "30 / 100\n",
      "31 / 100\n",
      "32 / 100\n",
      "33 / 100\n",
      "34 / 100\n",
      "35 / 100\n",
      "36 / 100\n",
      "37 / 100\n",
      "38 / 100\n",
      "39 / 100\n",
      "40 / 100\n",
      "41 / 100\n",
      "42 / 100\n",
      "43 / 100\n",
      "44 / 100\n",
      "45 / 100\n",
      "46 / 100\n",
      "47 / 100\n",
      "48 / 100\n",
      "49 / 100\n",
      "50 / 100\n",
      "51 / 100\n",
      "52 / 100\n",
      "53 / 100\n",
      "54 / 100\n",
      "55 / 100\n",
      "56 / 100\n",
      "57 / 100\n",
      "58 / 100\n",
      "59 / 100\n",
      "60 / 100\n",
      "61 / 100\n",
      "62 / 100\n",
      "63 / 100\n",
      "64 / 100\n",
      "65 / 100\n",
      "66 / 100\n",
      "67 / 100\n",
      "68 / 100\n",
      "69 / 100\n",
      "70 / 100\n",
      "71 / 100\n",
      "72 / 100\n",
      "73 / 100\n",
      "74 / 100\n",
      "75 / 100\n",
      "76 / 100\n",
      "77 / 100\n",
      "78 / 100\n",
      "79 / 100\n",
      "80 / 100\n",
      "81 / 100\n",
      "82 / 100\n",
      "83 / 100\n",
      "84 / 100\n",
      "85 / 100\n",
      "86 / 100\n",
      "87 / 100\n",
      "88 / 100\n",
      "89 / 100\n",
      "90 / 100\n",
      "91 / 100\n",
      "92 / 100\n",
      "93 / 100\n",
      "94 / 100\n",
      "95 / 100\n",
      "96 / 100\n",
      "97 / 100\n",
      "98 / 100\n",
      "99 / 100\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "learning_rate = 0.001\n",
    "epochs = 100\n",
    "model = PaulNet()\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "\n",
    "output=train(model, criterion, train_loader, test_loader, optimizer, epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success rate : 0.9849713740458015\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "\n",
    "\n",
    "count = 0\n",
    "for img, label in val_loader:\n",
    "    for i in range(64):\n",
    "        if model(img[i]).argmax() == label[i] :\n",
    "            count = count+1\n",
    "        \n",
    "print(f\"Success rate : {count/(len(val_loader)*64)}\")\n",
    "\n",
    "# 10 epoch   : 0.9788883587786259\n",
    "# 20 epochs  : 0.9809160305343512\n",
    "# 100 epochs : 0.9833015267175572\n",
    "# 100 AdamW  : 0.9853291984732825"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The image displays a 3\n"
     ]
    }
   ],
   "source": [
    "# running a small visual test\n",
    "\n",
    "for img in test_loader:\n",
    "    a = img\n",
    "arr = a[1]\n",
    "arr_ = np.squeeze(arr) # you can give axis attribute if you wanna squeeze in specific dimension\n",
    "plt.imshow(arr_)\n",
    "plt.show()\n",
    "print(\"The image displays a \" + str(model(a[1]).argmax().numpy()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submission file creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"submission.csv\", \"a\")\n",
    "f.write(\"ImageId,Label\\n\")\n",
    "\n",
    "i = 1\n",
    "for x in test_loader:\n",
    "    batch_pred = model(x)\n",
    "    for elt in batch_pred:\n",
    "        f.write(str(str(i) + \",\" + str(elt.argmax().numpy()) + \"\\n\"))\n",
    "        i = i + 1\n",
    "\n",
    "f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
