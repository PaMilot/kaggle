{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1faad7156d0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pylab as plt\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import torch.optim as optim\n",
    "\n",
    "# from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "import pandas as pd\n",
    "\n",
    "torch.manual_seed(2)\n",
    "\n",
    "# https://www.kaggle.com/competitions/digit-recognizer/overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNIST_data:\n",
    "    def __init__(self, train_path, test_path, batch_size, train_split_ratio):\n",
    "        self.train_path = train_path\n",
    "        self.test_path = test_path\n",
    "        self.batch_size = batch_size\n",
    "        self.train_split_ratio = train_split_ratio\n",
    "\n",
    "    class MNIST_train(Dataset):\n",
    "        def __init__(self, pixels, labels):\n",
    "            self.pixels = torch.tensor(pixels, dtype=torch.float32).view(-1, 1, 28, 28) / 255.0  # Normalize to [0, 1]\n",
    "            self.labels = torch.tensor(labels, dtype=torch.long)\n",
    "\n",
    "        def __len__(self):\n",
    "            return len(self.labels)\n",
    "\n",
    "        def __getitem__(self, idx):\n",
    "            return self.pixels[idx], self.labels[idx]\n",
    "\n",
    "    class MNIST_test(Dataset):\n",
    "        def __init__(self, pixels, test_df):\n",
    "            self.pixels = torch.tensor(pixels, dtype=torch.float32).view(-1, 1, 28, 28) / 255.0  # Normalize to [0, 1]\n",
    "            self.test_df = test_df\n",
    "\n",
    "        def __len__(self):\n",
    "            return len(self.test_df)\n",
    "\n",
    "        def __getitem__(self, idx):\n",
    "            return self.pixels[idx]\n",
    "\n",
    "\n",
    "    def make_train(self, batch_size=None):\n",
    "        batch_size = batch_size or self.batch_size\n",
    "        train_df = pd.read_csv(self.train_path)\n",
    "        labels = train_df['label'].values\n",
    "        pixels = train_df.drop(columns=['label']).values\n",
    "        mnist_dataset = self.MNIST_train(pixels, labels)\n",
    "\n",
    "        train_size = int(self.train_split_ratio * len(mnist_dataset))\n",
    "        val_size = len(mnist_dataset) - train_size\n",
    "        train_dataset, val_dataset = random_split(mnist_dataset, [train_size, val_size])\n",
    "\n",
    "        train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True,drop_last=True)\n",
    "        val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, drop_last=True)\n",
    "\n",
    "        return train_loader, val_loader\n",
    "    \n",
    "    def make_test(self, batch_size=None):\n",
    "        batch_size = batch_size or self.batch_size # should not be necessary as test datas are not used in the grid_search\n",
    "        test_df = pd.read_csv(self.test_path)\n",
    "        pixels = test_df.values\n",
    "\n",
    "        mnist_dataset_test = self.MNIST_test(pixels, test_df)\n",
    "        test_loader = DataLoader(mnist_dataset_test, batch_size=batch_size, shuffle=False, drop_last=False)\n",
    "        return test_loader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNIST:\n",
    "    def __init__(self, mnist_data):\n",
    "        self.mnist_data = mnist_data\n",
    "\n",
    "        # loaders :\n",
    "        self.train_loader, self.val_loader = mnist_data.make_train()\n",
    "        self.test_loader = mnist_data.make_test()\n",
    "\n",
    "    def train(self, model, criterion, optimizer, epochs=10, verbose = 0):\n",
    "        output = {'training_loss': []}  \n",
    "        for epoch in range(epochs):\n",
    "            if verbose : print(str(epoch) + \" / \" + str(epochs))\n",
    "            for i, (image, pred) in enumerate(self.train_loader):\n",
    "                optimizer.zero_grad()\n",
    "                z = model(image)\n",
    "                loss = criterion(z, pred)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                output['training_loss'].append(loss.data.item())\n",
    "        return output\n",
    "    \n",
    "\n",
    "    def evaluation(self, model):\n",
    "        model.eval()\n",
    "        count = 0\n",
    "        for img, label in self.val_loader:\n",
    "            for i in range(len(label)):\n",
    "                if model(img[i]).argmax() == label[i] :\n",
    "                    count = count+1\n",
    "        return count/(len(self.val_loader)*len(label))\n",
    "    \n",
    "    \n",
    "\n",
    "    def submit(self, model):\n",
    "        f = open(\"submission.csv\", \"a\")\n",
    "        f.write(\"ImageId,Label\\n\")\n",
    "        i = 1\n",
    "        for x in self.test_loader:\n",
    "            batch_pred = model(x)\n",
    "            for elt in batch_pred:\n",
    "                f.write(str(str(i) + \",\" + str(elt.argmax().numpy()) + \"\\n\"))\n",
    "                i = i + 1\n",
    "        f.close()\n",
    "        print(\"File created, ready to submit.\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNIST_gridSearch:\n",
    "    def __init__(self, model, mnist: MNIST, criterions, optimizers,\n",
    "                 epochs = [10],\n",
    "                 learning_rates = [0.001],\n",
    "                 batch_sizes = [32]):\n",
    "        self.model = model\n",
    "        self.mnist = mnist\n",
    "        self.criterions = criterions\n",
    "        self.optimizers = optimizers\n",
    "        self.epochs = epochs\n",
    "        self.learning_rates = learning_rates\n",
    "        self.batch_sizes = batch_sizes\n",
    "        self.total_iterations = len(criterions) * len(optimizers) * len(learning_rates) * len(batch_sizes) * len(epochs)\n",
    "\n",
    "    def gridSearch(self, verbose = 0) :\n",
    "        max = [0, 0, 0, 0, 0, 0] # opt, crit, epoch, l_rate, batch_size, score\n",
    "        iteration = 0\n",
    "        for batch_size in self.batch_sizes:\n",
    "            self.mnist.train_loader, self.mnist.val_loader = self.mnist.mnist_data.make_train(batch_size)\n",
    "            for optimizer in self.optimizers:\n",
    "                for criterion in self.criterions:\n",
    "                    for epoch in self.epochs:\n",
    "                        for l_rate in self.learning_rates:\n",
    "                            iteration += 1\n",
    "                            optim = optimizer(self.model.parameters(), lr=l_rate)\n",
    "                            self.mnist.train(self.model, criterion(), optim, epoch)\n",
    "\n",
    "                            score = self.mnist.evaluation(self.model)\n",
    "\n",
    "                            if verbose >= 1 : print(f\"Iteration {iteration} / {self.total_iterations} : score : {score}\")\n",
    "                            if score > max[5] :\n",
    "                                max = [optimizer, criterion, epoch, l_rate, batch_size, score]\n",
    "        \n",
    "        return max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PaulNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(PaulNet, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(1, 8, kernel_size=5, stride = 1, padding = 0)\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "\n",
    "        self.fc1 = nn.Linear(12*12*8, 56)\n",
    "        self.fc2 = nn.Linear(56, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.conv1(x))\n",
    "        out = self.pool1(out)\n",
    "        out = out.view(-1, 12*12*8)\n",
    "\n",
    "        out = F.relu(self.fc1(out))\n",
    "        out = self.fc2(out)\n",
    "        # out = F.softmax(out, dim=1)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learning_rate = 0.001\n",
    "# epochs = 10\n",
    "# model = PaulNet()\n",
    "\n",
    "# optimizer = optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "# criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# data = MNIST_data('train.csv', 'test.csv', 32, 0.8)\n",
    "# mnist = MNIST(data)\n",
    "\n",
    "# mnist.train(model, criterion, optimizer, epochs)\n",
    "# mnist.evaluation(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1 / 27 : score : 0.9589285714285715\n",
      "Iteration 2 / 27 : score : 0.9720238095238095\n",
      "Iteration 3 / 27 : score : 0.9809523809523809\n",
      "Iteration 4 / 27 : score : 0.9673809523809523\n",
      "Iteration 5 / 27 : score : 0.9769047619047619\n",
      "Iteration 6 / 27 : score : 0.9830952380952381\n",
      "Iteration 7 / 27 : score : 0.9780952380952381\n",
      "Iteration 8 / 27 : score : 0.976547619047619\n",
      "Iteration 9 / 27 : score : 0.9832142857142857\n",
      "Iteration 10 / 27 : score : 0.9847328244274809\n",
      "Iteration 11 / 27 : score : 0.9846135496183206\n",
      "Iteration 12 / 27 : score : 0.9921278625954199\n",
      "Iteration 13 / 27 : score : 0.9834208015267175\n",
      "Iteration 14 / 27 : score : 0.9824666030534351\n",
      "Iteration 15 / 27 : score : 0.9899809160305344\n",
      "Iteration 16 / 27 : score : 0.9767414122137404\n",
      "Iteration 17 / 27 : score : 0.9763835877862596\n",
      "Iteration 18 / 27 : score : 0.9862833969465649\n",
      "Iteration 19 / 27 : score : 0.9934398854961832\n",
      "Iteration 20 / 27 : score : 0.9921278625954199\n",
      "Iteration 21 / 27 : score : 0.9945133587786259\n",
      "Iteration 22 / 27 : score : 0.9854484732824428\n",
      "Iteration 23 / 27 : score : 0.9899809160305344\n",
      "Iteration 24 / 27 : score : 0.9930820610687023\n",
      "Iteration 25 / 27 : score : 0.9864026717557252\n",
      "Iteration 26 / 27 : score : 0.9835400763358778\n",
      "Iteration 27 / 27 : score : 0.9911736641221374\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[torch.optim.adamw.AdamW,\n",
       " torch.nn.modules.loss.CrossEntropyLoss,\n",
       " 1,\n",
       " 0.0005,\n",
       " 64,\n",
       " 0.9945133587786259]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_sizes = [16, 32, 64]\n",
    "lrs = [0.01, 0.007, 0.0005]\n",
    "epochs = [1, 2, 3]\n",
    "model = PaulNet()\n",
    "criterions = [nn.CrossEntropyLoss]\n",
    "optimizers = [optim.AdamW]\n",
    "\n",
    "data = MNIST_data('train.csv', 'test.csv', 32, 0.8)\n",
    "mnist = MNIST(data)\n",
    "grid_search = MNIST_gridSearch(model, mnist, criterions, optimizers, epochs, lrs, batch_sizes)\n",
    "\n",
    "best = grid_search.gridSearch(verbose = 1)\n",
    "best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [torch.optim.adamw.AdamW,\n",
    "#  torch.nn.modules.loss.CrossEntropyLoss,\n",
    "#  1,\n",
    "#  0.0005,\n",
    "#  64,\n",
    "#  0.9945133587786259]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
